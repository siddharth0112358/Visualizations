{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scattertext is a Python package that lets you interactively visualize how two categories of text are different from each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PytextRank + Scattertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytextrank in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.2.4)\n",
      "Requirement already satisfied: pygments>=2.7.4 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pytextrank) (2.12.0)\n",
      "Requirement already satisfied: graphviz>=0.13 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pytextrank) (0.20)\n",
      "Requirement already satisfied: networkx[default]>=2.6 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pytextrank) (2.8.3)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pytextrank) (1.7.3)\n",
      "Requirement already satisfied: spacy>=3.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pytextrank) (3.0.8)\n",
      "Requirement already satisfied: icecream>=2.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pytextrank) (2.1.3)\n",
      "Requirement already satisfied: executing>=0.3.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from icecream>=2.1->pytextrank) (0.8.3)\n",
      "Requirement already satisfied: asttokens>=2.0.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from icecream>=2.1->pytextrank) (2.0.5)\n",
      "Requirement already satisfied: colorama>=0.3.9 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from icecream>=2.1->pytextrank) (0.4.5)\n",
      "Requirement already satisfied: pandas>=1.3 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from networkx[default]>=2.6->pytextrank) (1.3.5)\n",
      "Collecting scipy>=1.7\n",
      "  Using cached scipy-1.9.1-cp38-cp38-win_amd64.whl (38.6 MB)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from networkx[default]>=2.6->pytextrank) (1.22.4)\n",
      "Requirement already satisfied: matplotlib>=3.4 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from networkx[default]>=2.6->pytextrank) (3.5.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (0.3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (3.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (3.0.9)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (0.6.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.27.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (0.7.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (1.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (8.0.16)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (1.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.4.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (2.0.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (62.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (4.64.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from spacy>=3.0->pytextrank) (0.9.1)\n",
      "Requirement already satisfied: six in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from asttokens>=2.0.1->icecream>=2.1->pytextrank) (1.15.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (4.33.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (9.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=3.4->networkx[default]>=2.6->pytextrank) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas>=1.3->networkx[default]>=2.6->pytextrank) (2022.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pathy>=0.3.5->spacy>=3.0->pytextrank) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy>=3.0->pytextrank) (3.10.0.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0->pytextrank) (3.3)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy>=3.0->pytextrank) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->spacy>=3.0->pytextrank) (2.1.1)\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.7.3\n",
      "    Uninstalling scipy-1.7.3:\n",
      "      Successfully uninstalled scipy-1.7.3\n",
      "Successfully installed scipy-1.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "causalnlp 0.6.0 requires Cython>=0.28.0, which is not installed.\n",
      "gensim 4.2.0 requires Cython==0.29.28, which is not installed.\n",
      "bioscrape 1.0.4 requires cython, which is not installed.\n",
      "tigramite 5.0.1.16 requires numpy==1.21.5, but you have numpy 1.22.4 which is incompatible.\n",
      "tigramite 5.0.1.16 requires scipy==1.8.0, but you have scipy 1.9.1 which is incompatible.\n",
      "causalnlp 0.6.0 requires scipy==1.4.1, but you have scipy 1.9.1 which is incompatible.\n",
      "causalnex 0.11.0 requires scikit-learn!=0.22.2.post1,!=0.24.1,<0.25.0,>=0.22.0; python_version < \"3.9\", but you have scikit-learn 1.1.2 which is incompatible.\n",
      "causalnex 0.11.0 requires scipy<1.7,>=1.2.0, but you have scipy 1.9.1 which is incompatible.\n",
      "vivarium-cobra 0.0.18 requires cobra==0.21.0, but you have cobra 0.5.4 which is incompatible.\n",
      "scispacy 0.5.0 requires spacy<3.3.0,>=3.2.0, but you have spacy 3.0.8 which is incompatible.\n",
      "pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.22.4 which is incompatible.\n",
      "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.9.1 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scattertext\n",
      "  Using cached scattertext-0.1.6-py3-none-any.whl (7.3 MB)\n",
      "Requirement already satisfied: flashtext in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scattertext) (2.7)\n",
      "Requirement already satisfied: scipy in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scattertext) (1.9.1)\n",
      "Requirement already satisfied: six in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scattertext) (1.15.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scattertext) (1.3.5)\n",
      "Requirement already satisfied: mock in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scattertext) (4.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\siddh\\appdata\\roaming\\python\\python38\\site-packages (from scattertext) (1.1.2)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scattertext) (0.13.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scattertext) (1.22.4)\n",
      "Requirement already satisfied: gensim>=4.0.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scattertext) (4.2.0)\n",
      "Collecting Cython==0.29.28\n",
      "  Using cached Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim>=4.0.0->scattertext) (5.2.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas->scattertext) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas->scattertext) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->scattertext) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->scattertext) (3.1.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from statsmodels->scattertext) (0.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from statsmodels->scattertext) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from packaging>=21.3->statsmodels->scattertext) (3.0.9)\n",
      "Installing collected packages: Cython, scattertext\n",
      "Successfully installed Cython-0.29.28 scattertext-0.1.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "causalnlp 0.6.0 requires scipy==1.4.1, but you have scipy 1.9.1 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytextrank -U\n",
    "%pip install scattertext -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/analytics-vidhya/visualizing-phrase-prominence-and-category-association-with-scattertext-and-pytextrank-f7a5f036d4d2#:~:text=Scattertext%20is%20a%20Python%20package,each%20other%20(Kessler%202017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytextrank.base.BaseTextRankFactory at 0x165dcf8b430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytextrank, spacy\n",
    "import scattertext as st\n",
    "import numpy as np\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"textrank\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df = st.SampleCorpora.ConventionData2012.get_data(\n",
    ").assign(\n",
    "    parse=lambda df: df.text.apply(nlp),\n",
    "    party=lambda df: df.party.apply(\n",
    "        {'democrat': 'Democratic', \n",
    "         'republican': 'Republican'}.get\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>Thank you. Thank you. Thank you. Thank you so ...</td>\n",
       "      <td>BARACK OBAMA</td>\n",
       "      <td>(Thank, you, ., Thank, you, ., Thank, you, ., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>Thank you so much. Tonight, I am so thrilled a...</td>\n",
       "      <td>MICHELLE OBAMA</td>\n",
       "      <td>(Thank, you, so, much, ., Tonight, ,, I, am, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>Thank you. It is a singular honor to be here t...</td>\n",
       "      <td>RICHARD DURBIN</td>\n",
       "      <td>(Thank, you, ., It, is, a, singular, honor, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>Hey, Delaware. \\nAnd my favorite Democrat, Jil...</td>\n",
       "      <td>JOSEPH BIDEN</td>\n",
       "      <td>(Hey, ,, Delaware, ., \\n, And, my, favorite, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>Hello. \\nThank you, Angie. I'm so proud of how...</td>\n",
       "      <td>JILL BIDEN</td>\n",
       "      <td>(Hello, ., \\n, Thank, you, ,, Angie, ., I, 'm,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        party                                               text  \\\n",
       "0  Democratic  Thank you. Thank you. Thank you. Thank you so ...   \n",
       "1  Democratic  Thank you so much. Tonight, I am so thrilled a...   \n",
       "2  Democratic  Thank you. It is a singular honor to be here t...   \n",
       "3  Democratic  Hey, Delaware. \\nAnd my favorite Democrat, Jil...   \n",
       "4  Democratic  Hello. \\nThank you, Angie. I'm so proud of how...   \n",
       "\n",
       "          speaker                                              parse  \n",
       "0    BARACK OBAMA  (Thank, you, ., Thank, you, ., Thank, you, ., ...  \n",
       "1  MICHELLE OBAMA  (Thank, you, so, much, ., Tonight, ,, I, am, s...  \n",
       "2  RICHARD DURBIN  (Thank, you, ., It, is, a, singular, honor, to...  \n",
       "3    JOSEPH BIDEN  (Hey, ,, Delaware, ., \\n, And, my, favorite, D...  \n",
       "4      JILL BIDEN  (Hello, ., \\n, Thank, you, ,, Angie, ., I, 'm,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scattertext\\termscoring\\ScaledFScore.py:129: RuntimeWarning: invalid value encountered in true_divide\n",
      "  precision = (cat_word_counts * 1. / (cat_word_counts + not_cat_word_counts))\n"
     ]
    }
   ],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(\n",
    "    convention_df,\n",
    "    category_col='party',\n",
    "    parsed_col='parse',\n",
    "    feats_from_spacy_doc=st.PyTextRankPhrases()\n",
    ").build(\n",
    ").compact(\n",
    "    st.AssociationCompactor(2000, use_non_text_features=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Democratic  Republican\n",
      "term                                        \n",
      "new plants              0.104446    0.000000\n",
      "jobs                    3.967825    2.860420\n",
      "construction workers    0.120949    0.000000\n",
      "more opportunity        0.175094    0.147941\n",
      "more Americans          0.177554    0.054976\n"
     ]
    }
   ],
   "source": [
    "term_category_scores = corpus.get_metadata_freq_df('')\n",
    "print(term_category_scores.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_ranks = np.argsort(\n",
    "    np.argsort(-term_category_scores, axis=0), \n",
    "axis=0) + 1\n",
    "metadata_descriptions = {\n",
    "    term: '<br/>' + '<br/>'.join(\n",
    "        '<b>%s</b> TextRank score rank: %s/%s' % (\n",
    "            cat, \n",
    "            term_ranks.loc[term, cat], \n",
    "            corpus.get_num_metadata()\n",
    "        )\n",
    "        for cat in corpus.get_categories()\n",
    "    )\n",
    "    for term in corpus.get_metadata()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_specific_prominence = term_category_scores.apply(\n",
    "    lambda row: (row.Democratic \n",
    "                 if row.Democratic > row.Republican \n",
    "                 else -row.Republican),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category='Democratic',\n",
    "    minimum_term_frequency=0,\n",
    "    pmi_threshold_coefficient=0,\n",
    "    width_in_pixels=1000,\n",
    "    transform=st.dense_rank,\n",
    "    metadata=corpus.get_df()['speaker'],\n",
    "    scores=category_specific_prominence,\n",
    "    sort_by_dist=False,\n",
    "    use_non_text_features=True,\n",
    "    topic_model_term_lists={term: [term] for term in         \n",
    "                            corpus.get_metadata()},\n",
    "    topic_model_preview_size=0,\n",
    "    metadata_descriptions=metadata_descriptions,\n",
    "    use_full_doc=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2361554"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category='Democratic',\n",
    "    minimum_term_frequency=0,\n",
    "    pmi_threshold_coefficient=0,\n",
    "    width_in_pixels=1000,\n",
    "    transform=st.dense_rank,\n",
    "    use_non_text_features=True,\n",
    "    metadata=corpus.get_df()['speaker'],\n",
    "    term_scorer=st.RankDifference(),\n",
    "    sort_by_dist=False,\n",
    "    topic_model_term_lists={term: [term] for term in \n",
    "                            corpus.get_metadata()},\n",
    "    topic_model_preview_size=0, \n",
    "    metadata_descriptions=metadata_descriptions,\n",
    "    use_full_doc=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2361081"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PhraseMachine and Scattertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scattertext\\termscoring\\ScaledFScore.py:296: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = cat_word_counts * 1. / cat_word_counts.sum()\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from scattertext import SampleCorpora, PhraseMachinePhrases, dense_rank, RankDifference, AssociationCompactor, produce_scattertext_explorer\n",
    "from scattertext.CorpusFromPandas import CorpusFromPandas\n",
    "corpus = CorpusFromPandas(\n",
    "    SampleCorpora.ConventionData2012.get_data(),\n",
    "    category_col='party',\n",
    "    text_col='text',\n",
    "    feats_from_spacy_doc=PhraseMachinePhrases(),\n",
    "    nlp=spacy.load('en_core_web_sm')\n",
    ").build().compact(AssociationCompactor(4000))\n",
    "html = produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category='democrat',\n",
    "    category_name='Democratic',\n",
    "    not_category_name='Republican',\n",
    "    minimum_term_frequency=0, \n",
    "    pmi_threshold_coefficient=0,\n",
    "    transform=st.dense_rank,\n",
    "    metadata=corpus.get_df()['speaker'],\n",
    "    term_scorer=st.RankDifference(),\n",
    "    width_in_pixels=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1432355"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df = st.SampleCorpora.ConventionData2012.get_data()\n",
    "convention_df['parse'] = convention_df['text'].apply(st.whitespace_nlp_with_sentences)\n",
    "corpus = (st.CorpusFromParsedDocuments(convention_df,\n",
    "                                       category_col='party',\n",
    "                                       parsed_col='parse')\n",
    "                                       .build()\n",
    "                                       .get_stoplisted_unigram_corpus()\n",
    "                                       .remove_infrequent_words(minimum_term_count=3, \n",
    "                                                                term_ranker=st.OncePerDocFrequencyRanker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189, 2149)\n",
      "189 2149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2149, 189)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "embeddings = TfidfTransformer().fit_transform(corpus.get_term_doc_mat())\n",
    "print(embeddings.shape)\n",
    "print(corpus.get_num_docs(), corpus.get_num_terms())\n",
    "embeddings = embeddings.T\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2149, 3) (3,) (3, 189)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "U, S, VT = svds(embeddings, k = 3, maxiter=20000, which='LM')\n",
    "print(U.shape, S.shape, VT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x_dim = 0; y_dim = 1;\n",
    "projection = pd.DataFrame({'term':corpus.get_terms(),\n",
    "                            'x':U.T[x_dim],\n",
    "                            'y':U.T[y_dim]}).set_index('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_pca_explorer(corpus,\n",
    "                               category='democrat',\n",
    "                               category_name='Democratic',\n",
    "                               not_category_name='Republican',\n",
    "                               projection=projection,\n",
    "                               metadata=convention_df['speaker'],\n",
    "                               width_in_pixels=1000,\n",
    "                               x_dim=x_dim,\n",
    "                               y_dim=y_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1804886"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_pca_explorer(corpus,\n",
    "                               category='democrat',\n",
    "                               category_name='Democratic',\n",
    "                               not_category_name='Republican',\n",
    "                               projection=projection,\n",
    "                               metadata=convention_df['speaker'],\n",
    "                               width_in_pixels=1000,\n",
    "                               scaler=st.scale_neg_1_to_1_with_zero_mean,\n",
    "                               x_dim=x_dim,\n",
    "                               y_dim=y_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1803849"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\decomposition\\_nmf.py:1477: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "convention_df = st.SampleCorpora.ConventionData2012.get_data()\n",
    "convention_df['parse'] = convention_df['text'].apply(st.whitespace_nlp_with_sentences)\n",
    "\n",
    "unigram_corpus = (st.CorpusFromParsedDocuments(convention_df,\n",
    "                                               category_col='party',\n",
    "                                               parsed_col='parse')\n",
    "                  .build().get_stoplisted_unigram_corpus())\n",
    "topic_model = st.SentencesForTopicModeling(unigram_corpus).get_topics_from_model(\n",
    "\tPipeline([\n",
    "\t\t('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "\t\t('nmf', (NMF(n_components=100, alpha=.1, l1_ratio=.5, random_state=0)))\n",
    "\t]),\n",
    "\tnum_terms_per_topic=20\n",
    ")\n",
    "  \n",
    "topic_feature_builder = st.FeatsFromTopicModel(topic_model)\n",
    "\n",
    "\n",
    "topic_corpus = st.CorpusFromParsedDocuments(\n",
    "\tconvention_df,\n",
    "\tcategory_col='party',\n",
    "\tparsed_col='parse',\n",
    "\tfeats_from_spacy_doc=topic_feature_builder\n",
    ").build()\n",
    "\n",
    "html = st.produce_scattertext_explorer(\n",
    "\ttopic_corpus,\n",
    "\tcategory='democrat',\n",
    "\tcategory_name='Democratic',\n",
    "\tnot_category_name='Republican',\n",
    "\twidth_in_pixels=1000,\n",
    "\tmetadata=convention_df['speaker'],\n",
    "\tuse_non_text_features=True,\n",
    "\tuse_full_doc=True,\n",
    "\tpmi_threshold_coefficient=0,\n",
    "\ttopic_model_term_lists=topic_feature_builder.get_top_model_term_lists(),\n",
    "\ttopic_model_preview_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1443560"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df = st.SampleCorpora.ConventionData2012.get_data()\n",
    "convention_df['parse'] = convention_df['text'].apply(st.whitespace_nlp_with_sentences)\n",
    "\n",
    "corpus = (st.CorpusFromParsedDocuments(convention_df, category_col='party', parsed_col='parse')\n",
    "          .build().get_stoplisted_unigram_corpus())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import umap\n",
    "# from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# html = st.produce_projection_explorer(corpus,\n",
    "#                                       word2vec_model=Word2Vec(size=100, window=5, min_count=10, workers=4),\n",
    "#                                       projection_model=umap.UMAP(min_dist=0.5, metric='cosine'),\n",
    "#                                       category='democrat',\n",
    "#                                       category_name='Democratic',\n",
    "#                                       not_category_name='Republican',\n",
    "#                                       metadata=convention_df.speaker)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicalized semiotic squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scattertext as st\n",
    "movie_df = st.SampleCorpora.RottenTomatoes.get_data()\n",
    "movie_df.category = movie_df.category.apply\\\n",
    "\t(lambda x: {'rotten': 'Negative', 'fresh': 'Positive', 'plot': 'Plot'}[x])\n",
    "corpus = st.CorpusFromPandas(\n",
    "\tmovie_df,\n",
    "\tcategory_col='category',\n",
    "\ttext_col='text',\n",
    "\tnlp=st.whitespace_nlp_with_sentences\n",
    ").build().get_unigram_corpus()\n",
    "\n",
    "semiotic_square = st.SemioticSquare(\n",
    "\tcorpus,\n",
    "\tcategory_a='Positive',\n",
    "\tcategory_b='Negative',\n",
    "\tneutral_categories=['Plot'],\n",
    "\tscorer=st.RankDifference(),\n",
    "\tlabels={'not_a_and_not_b': 'Plot Descriptions', 'a_and_b': 'Reviews'}\n",
    ")\n",
    "\n",
    "html = st.produce_semiotic_square_explorer(semiotic_square,\n",
    "                                           category_name='Positive',\n",
    "                                           not_category_name='Negative',\n",
    "                                           x_label='Fresh-Rotten',\n",
    "                                           y_label='Plot-Review',\n",
    "                                           neutral_category_name='Plot Description',\n",
    "                                           metadata=movie_df['movie_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1713825"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing scikit-learn text classification weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn-contrib-lightning\n",
      "  Downloading sklearn_contrib_lightning-0.6.2.post0-cp38-cp38-win_amd64.whl (643 kB)\n",
      "     -------------------------------------- 644.0/644.0 kB 8.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sklearn-contrib-lightning) (1.9.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sklearn-contrib-lightning) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\siddh\\appdata\\roaming\\python\\python38\\site-packages (from sklearn-contrib-lightning) (1.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sklearn-contrib-lightning) (1.22.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn-contrib-lightning) (3.1.0)\n",
      "Installing collected packages: sklearn-contrib-lightning\n",
      "Successfully installed sklearn-contrib-lightning-0.6.2.post0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ython-libsbml (c:\\users\\siddh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install sklearn-contrib-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from lightning.classification import CDClassifier\n",
    "import scattertext as st\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(\n",
    "\tsubset='train',\n",
    "\tremove=('headers', 'footers', 'quotes')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_X = vectorizer.fit_transform(newsgroups_train.data)\n",
    "count_vectorizer = CountVectorizer(vocabulary=vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromScikit(\n",
    "\tX=count_vectorizer.fit_transform(newsgroups_train.data),\n",
    "\ty=newsgroups_train.target,\n",
    "\tfeature_vocabulary=vectorizer.vocabulary_,\n",
    "\tcategory_names=newsgroups_train.target_names,\n",
    "\traw_texts=newsgroups_train.data\n",
    ").build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CDClassifier(penalty=\"l1/l2\",\n",
    "                   loss=\"squared_hinge\",\n",
    "                   multiclass=True,\n",
    "                   max_iter=20,\n",
    "                   alpha=1e-4,\n",
    "                   C=1.0 / tfidf_X.shape[0],\n",
    "                   tol=1e-3)\n",
    "clf.fit(tfidf_X, newsgroups_train.target)\n",
    "term_scores = clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "\tcorpus,\n",
    "\t'alt.atheism',\n",
    "\tscores=term_scores,\n",
    "\tuse_term_significance=False,\n",
    "\tterms_to_include=st.AutoTermSelector.get_selected_terms(corpus, term_scores, 4000),\n",
    "\tmetadata = ['/'.join(fn.split('/')[-2:]) for fn in newsgroups_train.filenames]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "#                                      remove=('headers', 'footers', 'quotes'))\n",
    "# X_test = vectorizer.transform(newsgroups_test.data)\n",
    "# pred = clf.predict(X_test)\n",
    "# f1 = f1_score(pred, newsgroups_test.target, average='micro')\n",
    "# print(\"Microaveraged F1 score\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16676890"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"Convention-Visualization.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentencePiece Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import re\n",
    "import scattertext as st\n",
    "\n",
    "convention_df = st.SampleCorpora.ConventionData2012.get_data()\n",
    "convention_df['parse'] = convention_df.text.apply(st.whitespace_nlp_with_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Thank you. Thank you. Thank you. Thank you so ...</td>\n",
       "      <td>BARACK OBAMA</td>\n",
       "      <td>(thank, you, ., thank, you, ., thank, you, ., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Thank you so much. Tonight, I am so thrilled a...</td>\n",
       "      <td>MICHELLE OBAMA</td>\n",
       "      <td>(thank, you, so, much, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Thank you. It is a singular honor to be here t...</td>\n",
       "      <td>RICHARD DURBIN</td>\n",
       "      <td>(thank, you, ., it, is, a, singular, honor, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Hey, Delaware. \\nAnd my favorite Democrat, Jil...</td>\n",
       "      <td>JOSEPH BIDEN</td>\n",
       "      <td>(hey, ,, delaware, ., and, my, favorite, democ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>democrat</td>\n",
       "      <td>Hello. \\nThank you, Angie. I'm so proud of how...</td>\n",
       "      <td>JILL BIDEN</td>\n",
       "      <td>(hello, ., thank, you, ,, angie, ., i, ', m, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      party                                               text  \\\n",
       "0  democrat  Thank you. Thank you. Thank you. Thank you so ...   \n",
       "1  democrat  Thank you so much. Tonight, I am so thrilled a...   \n",
       "2  democrat  Thank you. It is a singular honor to be here t...   \n",
       "3  democrat  Hey, Delaware. \\nAnd my favorite Democrat, Jil...   \n",
       "4  democrat  Hello. \\nThank you, Angie. I'm so proud of how...   \n",
       "\n",
       "          speaker                                              parse  \n",
       "0    BARACK OBAMA  (thank, you, ., thank, you, ., thank, you, ., ...  \n",
       "1  MICHELLE OBAMA                          (thank, you, so, much, .)  \n",
       "2  RICHARD DURBIN  (thank, you, ., it, is, a, singular, honor, to...  \n",
       "3    JOSEPH BIDEN  (hey, ,, delaware, ., and, my, favorite, democ...  \n",
       "4      JILL BIDEN  (hello, ., thank, you, ,, angie, ., i, ', m, s...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convention_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "def train_sentence_piece_tokenizer(documents, vocab_size):\n",
    "    '''\n",
    "    :param documents: list-like, a list of str documents\n",
    "    :vocab_size int: the size of the vocabulary to output\n",
    "    :return sentencepiece.SentencePieceProcessor\n",
    "    '''\n",
    "    sp = None\n",
    "    with tempfile.NamedTemporaryFile(delete=True) as tempf:\n",
    "        with tempfile.NamedTemporaryFile(delete=True) as tempm:\n",
    "            tempf.write(('\\n'.join(documents)).encode())\n",
    "            mod = spm.SentencePieceTrainer.Train(input = tempf.name, model_prefix = tempm.name, vocab_size = vocab_size)\n",
    "            sp = spm.SentencePieceProcessor()\n",
    "            sp.load(tempm.name + '.model')\n",
    "    return sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = train_sentence_piece_tokenizer(convention_df.text.values, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(\n",
    "    convention_df,\n",
    "    parsed_col='parse',\n",
    "    category_col='party',\n",
    "    feats_from_spacy_doc=st.FeatsFromSentencePiece(sp)\n",
    ").build()\n",
    "\n",
    "html = st.produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category='democrat',\n",
    "    category_name='Democratic',\n",
    "    not_category_name='Republican',\n",
    "    sort_by_dist=False,\n",
    "    metadata=convention_df['party'] + ': ' + convention_df['speaker'],\n",
    "    term_scorer=st.RankDifference(),\n",
    "    transform=st.Scalers.dense_rank,\n",
    "    use_non_text_features=True,\n",
    "    use_full_doc=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e224e6ffc6a79d997e70a56e2eea6596a33799be7332df00b55415489d25d351"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
